{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwr04bxQcExd",
        "outputId": "707e4d7d-8f82-47c9-f59f-3b4d990edad8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJHHI0XhcBGP",
        "outputId": "3056f1cd-6482-4c17-8290-63e0cd19f44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nona\n",
            "  Downloading nona-0.0.2-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.10/dist-packages (from nona) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1 in /usr/local/lib/python3.10/dist-packages (from nona) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=1 in /usr/local/lib/python3.10/dist-packages (from nona) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.10/dist-packages (from nona) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->nona) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->nona) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->nona) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1->nona) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1->nona) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1->nona) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1->nona) (1.16.0)\n",
            "Installing collected packages: nona\n",
            "Successfully installed nona-0.0.2\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.25.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch-tabnet-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install nona\n",
        "!pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add all required libraries"
      ],
      "metadata": {
        "id": "MDnLVgypc_xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from nona.nona import nona\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "dwkhkhkCdAsi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let’s add 4 features to the dataset to train the model:\n",
        "* Systolic blood pressure\n",
        "* Heart rate\n",
        "*   Breathing rate\n",
        "*   Temperature"
      ],
      "metadata": {
        "id": "rHM7eAPydDCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_chartevents(file_path, output_path, item_ids):\n",
        "    \"\"\" collecting features of the dataset\n",
        "\n",
        "    Keyword arguments:\n",
        "    file_path -- path to the file\n",
        "    output_path -- path to the output file\n",
        "    item_ids -- list of item ids\n",
        "\n",
        "    \"\"\"\n",
        "    item_ids_set = set(item_ids)\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    with open(file_path) as f:\n",
        "        headers = f.readline().replace('\\n', '').split(',')\n",
        "        i = 0\n",
        "        for line in tqdm(f):\n",
        "            values = line.replace('\\n', '').split(',')\n",
        "            subject_id = values[0]\n",
        "            item_id = values[6]\n",
        "            valuenum = values[8]\n",
        "            if item_id in item_ids_set:\n",
        "                if subject_id not in result:\n",
        "                    result[subject_id] = {}\n",
        "                result[subject_id][item_id] = valuenum\n",
        "            i += 1\n",
        "\n",
        "    table = pd.DataFrame.from_dict(result, orient='index')\n",
        "    table['subject_id'] = table.index\n",
        "\n",
        "    table.to_csv(output_path, index=False)\n",
        "\n",
        "item_ids = [str(x) for x in [225309, 220045, 220210, 223762]]\n",
        "file_path = './MIMIC/icu/chartevents.csv'\n",
        "output_path = 'df.csv'\n",
        "\n",
        "process_chartevents(file_path, output_path, item_ids)"
      ],
      "metadata": {
        "id": "_zc3729_dF4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's add a column to the dataset with a target - whether a person has sepsis or not"
      ],
      "metadata": {
        "id": "K18vjRaAdJnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_diagnosis_column(drgcodes_path, merged_data_path, output_path):\n",
        "    \"\"\"Add diagnosis column to dataset.\n",
        "\n",
        "    Keyword arguments:\n",
        "    drgcodes_path -- path to the drgcodes file\n",
        "    merged_data_path -- path to the file with features\n",
        "    output_path -- path to the output file\n",
        "\n",
        "    \"\"\"\n",
        "    drgcodes = pd.read_csv(drgcodes_path)\n",
        "    merged_data = pd.read_csv(merged_data_path)\n",
        "\n",
        "    drgcodes['drg_code'] = pd.to_numeric(drgcodes['drg_code'], errors='coerce')\n",
        "    merged_data['diagnosis'] = 0\n",
        "\n",
        "    target_subjects = drgcodes.loc[drgcodes['drg_code'].isin([870, 871, 872]), 'subject_id']\n",
        "    merged_data.loc[merged_data['subject_id'].isin(target_subjects), 'diagnosis'] = 1\n",
        "\n",
        "    merged_data.to_csv(output_path, index=False)\n",
        "\n",
        "drgcodes_path = './MIMIC/hosp/drgcodes.csv'\n",
        "merged_data_path = './df.csv'\n",
        "output_path = 'df_with_target.csv'\n",
        "\n",
        "add_diagnosis_column(drgcodes_path, merged_data_path, output_path)"
      ],
      "metadata": {
        "id": "rl0T3JYgdOBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### There are a lot of gaps in our data, so let's use the NoNa library and fill them in"
      ],
      "metadata": {
        "id": "HlYIeJa7dQvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def impute_data(input_path, output_path, features):\n",
        "    \"\"\"Fill in the blanks.\n",
        "\n",
        "    Keyword arguments:\n",
        "    input_path -- path to the input file\n",
        "    output_path -- path to the output file\n",
        "    features -- list of features\n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    X = df[features]\n",
        "\n",
        "    nona(\n",
        "        data=X,\n",
        "        algreg=make_pipeline(StandardScaler(with_mean=False), Ridge(alpha=0.1)),\n",
        "        algclass=RandomForestClassifier(max_depth=2, random_state=0)\n",
        "    )\n",
        "\n",
        "    df[features] = X\n",
        "\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "input_path = 'df_with_target.csv'\n",
        "output_path = 'df_with_target_imputed.csv'\n",
        "features = ['225309', '220045', '220210', '223762']\n",
        "\n",
        "impute_data(input_path, output_path, features)"
      ],
      "metadata": {
        "id": "8QZzdrKudULD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's divide the dataset into training and test sets, then balance the training set by target"
      ],
      "metadata": {
        "id": "CgGXMQhBe5ML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_and_save_data(input_path, test_size, random_state, features, target, resampled_output_path, test_output_path):\n",
        "    \"\"\"We divide the data into train and test. Getting rid of class imbalance in train.\n",
        "\n",
        "    Keyword arguments:\n",
        "    input_path -- path to the input file\n",
        "    test_size -- size of the test set\n",
        "    random_state -- random state\n",
        "    features -- list of features\n",
        "    target -- target column\n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    train_data, test_data = train_test_split(df, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    X_train = train_data[features]\n",
        "    y_train = train_data[target]\n",
        "\n",
        "    smote = SMOTE(random_state=random_state)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X_train.columns), pd.DataFrame(y_resampled, columns=[target])], axis=1)\n",
        "\n",
        "    df_resampled.to_csv(resampled_output_path, index=False)\n",
        "    test_data.to_csv(test_output_path, index=False)\n",
        "\n",
        "    return df_resampled, test_data\n",
        "\n",
        "input_path = 'df_with_target_imputed.csv'\n",
        "test_size = 0.4\n",
        "random_state = 42\n",
        "features = ['225309', '220045', '220210', '223762']\n",
        "target = 'SepsisLabel'\n",
        "resampled_output_path = 'train_data_MEWS.csv'\n",
        "test_output_path = 'test_data.csv'\n",
        "\n",
        "df_resampled, test_data = prepare_and_save_data(input_path, test_size, random_state, features, target, resampled_output_path, test_output_path)"
      ],
      "metadata": {
        "id": "2FQxd7otdb5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make sure that the classes in the training data are balanced"
      ],
      "metadata": {
        "id": "jBTDi5nxexsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Лаба ML/transformers/train_data_MEWS.csv')"
      ],
      "metadata": {
        "id": "mKkrH6mbdgRo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(df['diagnosis'] == 0))\n",
        "print(sum(df['diagnosis'] == 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex5FzoVcdwX3",
        "outputId": "cd2cbf69-e357-403c-ee00-30466d1b1087"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27249\n",
            "27249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's divide the test dataset into test and validation ones, then balance the samples"
      ],
      "metadata": {
        "id": "QX0nvzmcfN3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resample_test_val_data(input_path, test_size, random_state, features, target, test_output_path, val_output_path):\n",
        "    \"\"\"We divide the data into test and validation. Getting rid of class imbalance in test and in validation.\n",
        "\n",
        "    Keyword arguments:\n",
        "    input_path -- path to the input file\n",
        "    test_size -- size of the test set\n",
        "    random_state -- random state\n",
        "    features -- list of features\n",
        "    target -- target column\n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_path)\n",
        "    data = df.drop(['subject_id'], axis=1)\n",
        "    test_data, val_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    smote1 = SMOTE(random_state=42)\n",
        "    X1 = test_data[features]\n",
        "    y1 = test_data[target]\n",
        "    X_resampled1, y_resampled1 = smote1.fit_resample(X1, y1)\n",
        "    df_resampled1 = pd.concat([pd.DataFrame(X_resampled1, columns=features), pd.DataFrame(y_resampled1, columns=[target])], axis=1)\n",
        "    df_resampled1.to_csv(test_output_path, index=False)\n",
        "\n",
        "    smote2 = SMOTE(random_state=42)\n",
        "    X2 = val_data[features]\n",
        "    y2 = val_data[target]\n",
        "    X_resampled2, y_resampled2 = smote2.fit_resample(X2, y2)\n",
        "    df_resampled2 = pd.concat([pd.DataFrame(X_resampled2, columns=features), pd.DataFrame(y_resampled2, columns=[target])], axis=1)\n",
        "    df_resampled2.to_csv(val_output_path, index=False)\n",
        "\n",
        "input_path = 'test_data_31.csv'\n",
        "test_size = 0.4\n",
        "random_state = 42\n",
        "features = ['225309', '220045', '220210', '223762']\n",
        "target = 'diagnosis'\n",
        "test_output_path = 'test_resampled_data.csv'\n",
        "val_output_path = 'val_resampled_data.csv'\n",
        "resample_test_val_data(input_path, test_size, random_state, features, target, test_output_path, val_output_path)"
      ],
      "metadata": {
        "id": "LeQJVPivfJXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making sure the classes are balanced"
      ],
      "metadata": {
        "id": "Zm1rSSaKfW7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Лаба ML/transformers/val_resampled_data_MEWS.csv')"
      ],
      "metadata": {
        "id": "ECAy4MOleAKI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(df['diagnosis'] == 0))\n",
        "print(sum(df['diagnosis'] == 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8plOt8HneO4w",
        "outputId": "66649d83-f99a-4a42-970d-5ed9673b5360"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9128\n",
            "9128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Лаба ML/transformers/test_resampled_data_MEWS.csv')"
      ],
      "metadata": {
        "id": "rxIeuH_DeJs3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(df['diagnosis'] == 0))\n",
        "print(sum(df['diagnosis'] == 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K8cBpDveSkr",
        "outputId": "62ca71f3-2e38-4482-c4f5-feb6aa511f57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9065\n",
            "9065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's use the TabNet transformer as a learning model. Let's train the model with selected hyperparameters, preserve the importance of the features and the model itself"
      ],
      "metadata": {
        "id": "mLVD6yWTflPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tabnet_model(train_path, val_path, feature_importances_path, model_save_path, optimizer_params, scheduler_params, pretraining_lr=0.05, training_lr=0.05, mask_type='sparsemax', pretraining_ratio=1.0, max_epochs=200, patience=50):\n",
        "    \"\"\"Model training, preserving the importance of features and saving the model.\n",
        "\n",
        "    Keyword arguments:\n",
        "    train_path -- path to the train data\n",
        "    val_path -- path to the validation data\n",
        "    feature_importances_path -- path to the file with feature importances\n",
        "    model_save_path -- path to the model\n",
        "    optimizer_params -- optimizer parameters\n",
        "    scheduler_params -- scheduler parameters\n",
        "    pretraining_lr -- learning rate for pretraining (default 0.05)\n",
        "    training_lr -- learning rate for training (default 0.05)\n",
        "    mask_type -- mask type (default 'sparsemax')\n",
        "    pretraining_ratio -- ratio of pretraining data (default 1.0)\n",
        "    max_epochs -- maximum number of epochs (default 200)\n",
        "    patience -- patience (default 50)\n",
        "\n",
        "    \"\"\"\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    val_data = pd.read_csv(val_path)\n",
        "\n",
        "    X_train = train_data.drop(['diagnosis'], axis=1)\n",
        "    y_train = train_data['diagnosis']\n",
        "\n",
        "    X_val = val_data.drop(['diagnosis'], axis=1)\n",
        "    y_val = val_data['diagnosis']\n",
        "\n",
        "    unsupervised_model = TabNetPretrainer(\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params=dict(lr=pretraining_lr),\n",
        "        mask_type=mask_type\n",
        "    )\n",
        "\n",
        "    unsupervised_model.fit(\n",
        "        X_train=X_train.values,\n",
        "        eval_set=[X_val.values],\n",
        "        pretraining_ratio=pretraining_ratio,\n",
        "    )\n",
        "\n",
        "    clf = TabNetClassifier(\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params=dict(lr=training_lr),\n",
        "        scheduler_params=scheduler_params,\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "        mask_type=mask_type\n",
        "    )\n",
        "\n",
        "    clf.fit(\n",
        "        X_train=X_train.values, y_train=y_train.values,\n",
        "        eval_set=[(X_val.values, y_val.values)],\n",
        "        eval_metric=['auc'],\n",
        "        max_epochs=max_epochs,\n",
        "        patience=patience,\n",
        "        from_unsupervised=unsupervised_model\n",
        "    )\n",
        "\n",
        "    with open(feature_importances_path, 'w') as f:\n",
        "        f.write(f'{clf.feature_importances_}')\n",
        "\n",
        "    clf.save_model(model_save_path)\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Лаба ML/transformers/train_data_MEWS.csv'\n",
        "val_path = '/content/drive/MyDrive/Лаба ML/transformers/val_resampled_data_MEWS.csv'\n",
        "feature_importances_path = 'fimp.txt'\n",
        "model_save_path = './tabnet_model_test_1'\n",
        "optimizer_params = dict(lr=0.05)\n",
        "scheduler_params = {\n",
        "    \"step_size\": 10,\n",
        "    \"gamma\": 0.9\n",
        "}\n",
        "\n",
        "train_tabnet_model(train_path, val_path, feature_importances_path, model_save_path, optimizer_params, scheduler_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkWXme5ffaWt",
        "outputId": "8063bacd-04d5-4b02-f2ae-fe27209eedcb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 36.84088| val_0_unsup_loss_numpy: 3.5068378504386677e+28|  0:00:05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/metrics.py:59: RuntimeWarning: overflow encountered in square\n",
            "  reconstruction_errors = np.multiply(errors, obf_vars) ** 2\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1  | loss: 1.14778 | val_0_unsup_loss_numpy: inf     |  0:00:09s\n",
            "epoch 2  | loss: 1.02261 | val_0_unsup_loss_numpy: inf     |  0:00:12s\n",
            "epoch 3  | loss: 1.02943 | val_0_unsup_loss_numpy: inf     |  0:00:16s\n",
            "epoch 4  | loss: 1.00712 | val_0_unsup_loss_numpy: inf     |  0:00:21s\n",
            "epoch 5  | loss: 1.00862 | val_0_unsup_loss_numpy: inf     |  0:00:24s\n",
            "epoch 6  | loss: 1.01511 | val_0_unsup_loss_numpy: inf     |  0:00:27s\n",
            "epoch 7  | loss: 1.00804 | val_0_unsup_loss_numpy: inf     |  0:00:32s\n",
            "epoch 8  | loss: 1.00626 | val_0_unsup_loss_numpy: inf     |  0:00:36s\n",
            "epoch 9  | loss: 1.01127 | val_0_unsup_loss_numpy: inf     |  0:00:39s\n",
            "epoch 10 | loss: 1.00864 | val_0_unsup_loss_numpy: inf     |  0:00:43s\n",
            "\n",
            "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_unsup_loss_numpy = 3.5068378504386677e+28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.68376 | val_0_auc: 0.44233 |  0:00:04s\n",
            "epoch 1  | loss: 0.66186 | val_0_auc: 0.51559 |  0:00:09s\n",
            "epoch 2  | loss: 0.66131 | val_0_auc: 0.58031 |  0:00:12s\n",
            "epoch 3  | loss: 0.65913 | val_0_auc: 0.58202 |  0:00:15s\n",
            "epoch 4  | loss: 0.65881 | val_0_auc: 0.59011 |  0:00:18s\n",
            "epoch 5  | loss: 0.65877 | val_0_auc: 0.59297 |  0:00:23s\n",
            "epoch 6  | loss: 0.65716 | val_0_auc: 0.58709 |  0:00:26s\n",
            "epoch 7  | loss: 0.65881 | val_0_auc: 0.58719 |  0:00:29s\n",
            "epoch 8  | loss: 0.65716 | val_0_auc: 0.59137 |  0:00:32s\n",
            "epoch 9  | loss: 0.65695 | val_0_auc: 0.59014 |  0:00:36s\n",
            "epoch 10 | loss: 0.65877 | val_0_auc: 0.58219 |  0:00:40s\n",
            "epoch 11 | loss: 0.65522 | val_0_auc: 0.58473 |  0:00:43s\n",
            "epoch 12 | loss: 0.65521 | val_0_auc: 0.57556 |  0:00:46s\n",
            "epoch 13 | loss: 0.65405 | val_0_auc: 0.56469 |  0:00:49s\n",
            "epoch 14 | loss: 0.65396 | val_0_auc: 0.57425 |  0:00:54s\n",
            "epoch 15 | loss: 0.65388 | val_0_auc: 0.58365 |  0:00:57s\n",
            "epoch 16 | loss: 0.65396 | val_0_auc: 0.5815  |  0:01:00s\n",
            "epoch 17 | loss: 0.65441 | val_0_auc: 0.58327 |  0:01:03s\n",
            "epoch 18 | loss: 0.65294 | val_0_auc: 0.57091 |  0:01:07s\n",
            "epoch 19 | loss: 0.65323 | val_0_auc: 0.56507 |  0:01:11s\n",
            "epoch 20 | loss: 0.65206 | val_0_auc: 0.56343 |  0:01:14s\n",
            "epoch 21 | loss: 0.65266 | val_0_auc: 0.57659 |  0:01:17s\n",
            "epoch 22 | loss: 0.65218 | val_0_auc: 0.58154 |  0:01:20s\n",
            "epoch 23 | loss: 0.65172 | val_0_auc: 0.56491 |  0:01:24s\n",
            "epoch 24 | loss: 0.65177 | val_0_auc: 0.58239 |  0:01:28s\n",
            "epoch 25 | loss: 0.65288 | val_0_auc: 0.56962 |  0:01:31s\n",
            "epoch 26 | loss: 0.65307 | val_0_auc: 0.57716 |  0:01:34s\n",
            "epoch 27 | loss: 0.65507 | val_0_auc: 0.56765 |  0:01:38s\n",
            "epoch 28 | loss: 0.65135 | val_0_auc: 0.58738 |  0:01:41s\n",
            "epoch 29 | loss: 0.65289 | val_0_auc: 0.56267 |  0:01:44s\n",
            "epoch 30 | loss: 0.65194 | val_0_auc: 0.58014 |  0:01:47s\n",
            "epoch 31 | loss: 0.65104 | val_0_auc: 0.57939 |  0:01:51s\n",
            "epoch 32 | loss: 0.65155 | val_0_auc: 0.58196 |  0:01:55s\n",
            "epoch 33 | loss: 0.65195 | val_0_auc: 0.58046 |  0:01:57s\n",
            "epoch 34 | loss: 0.65204 | val_0_auc: 0.58029 |  0:02:01s\n",
            "epoch 35 | loss: 0.65111 | val_0_auc: 0.58052 |  0:02:05s\n",
            "epoch 36 | loss: 0.65179 | val_0_auc: 0.56979 |  0:02:08s\n",
            "epoch 37 | loss: 0.65026 | val_0_auc: 0.58373 |  0:02:11s\n",
            "epoch 38 | loss: 0.64999 | val_0_auc: 0.57339 |  0:02:14s\n",
            "epoch 39 | loss: 0.65064 | val_0_auc: 0.58118 |  0:02:18s\n",
            "epoch 40 | loss: 0.64986 | val_0_auc: 0.56963 |  0:02:22s\n",
            "epoch 41 | loss: 0.64975 | val_0_auc: 0.57631 |  0:02:25s\n",
            "epoch 42 | loss: 0.65019 | val_0_auc: 0.5773  |  0:02:28s\n",
            "epoch 43 | loss: 0.64901 | val_0_auc: 0.58086 |  0:02:31s\n",
            "epoch 44 | loss: 0.64827 | val_0_auc: 0.57939 |  0:02:35s\n",
            "epoch 45 | loss: 0.64927 | val_0_auc: 0.57069 |  0:02:39s\n",
            "epoch 46 | loss: 0.64867 | val_0_auc: 0.56319 |  0:02:42s\n",
            "epoch 47 | loss: 0.64962 | val_0_auc: 0.57471 |  0:02:45s\n",
            "epoch 48 | loss: 0.64961 | val_0_auc: 0.57421 |  0:02:49s\n",
            "epoch 49 | loss: 0.64862 | val_0_auc: 0.57618 |  0:02:53s\n",
            "epoch 50 | loss: 0.64877 | val_0_auc: 0.57102 |  0:02:56s\n",
            "epoch 51 | loss: 0.6488  | val_0_auc: 0.57267 |  0:02:59s\n",
            "epoch 52 | loss: 0.64902 | val_0_auc: 0.57675 |  0:03:02s\n",
            "epoch 53 | loss: 0.6489  | val_0_auc: 0.58378 |  0:03:06s\n",
            "epoch 54 | loss: 0.64909 | val_0_auc: 0.58719 |  0:03:09s\n",
            "epoch 55 | loss: 0.64961 | val_0_auc: 0.58745 |  0:03:12s\n",
            "\n",
            "Early stopping occurred at epoch 55 with best_epoch = 5 and best_val_0_auc = 0.59297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved model at ./tabnet_model_test_1.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's find out what signs the model paid the most attention to"
      ],
      "metadata": {
        "id": "S6uiRH0BjdUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/fimp.txt'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "    print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3z4t5U6ijU1",
        "outputId": "0a7344e0-5263-4b18-8784-3f23349aac33"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.29729455 0.21506934 0.48763611]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the importance of features"
      ],
      "metadata": {
        "id": "VYL3H9akkiXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "feature_importances = [0.0, 0.29729455, 0.21506934, 0.48763611]\n",
        "\n",
        "importance_df = pd.DataFrame({'Feature': ['SBP','HR','RR','temp'], 'Importance': feature_importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "sns.barplot(data=importance_df, x='Importance', y='Feature')\n",
        "plt.title('Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "Fha4ZQhsiR7e",
        "outputId": "d1b36bc2-9eea-446f-bf73-44895e6fe774"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's look at the metrics obtained as a result of prediction on the test sample"
      ],
      "metadata": {
        "id": "meiYxNIjk8cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_tabnet_model(model_path, test_data_path, metrics_output_path):\n",
        "    \"\"\"Evaluate the model.\n",
        "\n",
        "    Keyword arguments:\n",
        "    model_path -- path to the model\n",
        "    test_data_path -- path to the test data\n",
        "    metrics_output_path -- path to the output file\n",
        "\n",
        "    \"\"\"\n",
        "    loaded_clf = TabNetClassifier()\n",
        "    loaded_clf.load_model(model_path)\n",
        "\n",
        "    test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "    X_test = test_data.drop(['diagnosis'], axis=1)\n",
        "    y_test = test_data['diagnosis']\n",
        "\n",
        "    result = loaded_clf.predict(X_test.values)\n",
        "\n",
        "    accuracy = (result == y_test.values).mean()\n",
        "    precision = precision_score(y_test.values, result)\n",
        "    recall = recall_score(y_test.values, result)\n",
        "    f1 = f1_score(y_test.values, result)\n",
        "\n",
        "    with open(metrics_output_path, 'w') as file:\n",
        "        file.write(f'Accuracy: {accuracy}\\n')\n",
        "        file.write(f'Precision: {precision}\\n')\n",
        "        file.write(f'Recall: {recall}\\n')\n",
        "        file.write(f'F1-score: {f1}\\n')\n",
        "        file.close()\n",
        "\n",
        "model_path = \"./tabnet_model_test_1.zip\"\n",
        "test_data_path = '/content/drive/MyDrive/Лаба ML/transformers/test_resampled_data_MEWS.csv'\n",
        "metrics_output_path = \"metrics.txt\"\n",
        "\n",
        "evaluate_tabnet_model(model_path, test_data_path, metrics_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PEBEVyYkoq7",
        "outputId": "6b9d67c0-7686-4899-dd55-dc80d8cbd67c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/metrics.txt'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "    print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgjlr8iWk57g",
        "outputId": "04581a41-a8aa-487f-beb8-810936e8197a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5257584114726972\n",
            "Precision: 0.5143842789379659\n",
            "Recall: 0.9211252068394925\n",
            "F1-score: 0.660131235670804\n",
            "\n"
          ]
        }
      ]
    }
  ]
}